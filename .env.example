# Application Configuration
LOG_LEVEL="INFO"
PDFS_DIR="pdfs"
INDICES_DIR="indices"
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
CHUNKING_MODE="both" # 'tokens', 'paragraphs', 'both'
EMBEDDING_MODEL_NAME="sentence-transformers/all-mpnet-base-v2"
OLLAMA_MODEL_NAME="llama3.2"
OLLAMA_HOST="http://localhost:11434" # Ensure Ollama server is accessible here
OLLAMA_TIMEOUT=120 # Timeout for Ollama client requests in seconds

# Retriever Configuration
RETRIEVAL_K=4
INITIAL_VECTOR_K=50
VECTOR_DISTANCE_THRESHOLD=1.0 # L2 distance, lower is more similar
FINAL_BM25_K=6
DEVICE_CONFIGURATION="cuda" # Device (like “cuda”, “cpu”, “mps”, “npu”) that should be used for computation. If None, checks if a GPU can be used.
# Set the device for the embedding model

# API Configuration
API_PDF_MAX_SIZE_MB=100 # Max PDF upload size in MB
UVICORN_HOST="0.0.0.0"
UVICORN_PORT=8000
UVICORN_TIMEOUT_KEEP_ALIVE=120 # Uvicorn keep-alive timeout

# Cache Configuration
RESPONSE_CACHE_MAX_SIZE=100
RESPONSE_CACHE_TTL_SECONDS=3600
SERVICE_CACHE_MAX_SIZE=10 # Max number of Index/Query service instances (and their vector stores) to keep in memory
